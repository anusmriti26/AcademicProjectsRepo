{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VqiPUt1wtlZ2",
    "outputId": "af896d8a-a3fe-4059-f847-25330999db71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/MyDrive/Colab255/GP5\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive to access data and save files\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define the home directory and change to that directory\n",
    "HOME = \"/content/drive/MyDrive/Colab255/GP5\"\n",
    "%cd {HOME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rBpX6LjYPCmK",
    "outputId": "ab8d439f-d7a3-4c60-fb1a-a9f6080f5eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "planttraits2024.zip\n"
     ]
    }
   ],
   "source": [
    "# List files in the home directory\n",
    "\n",
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fUoqEwRiunbZ",
    "outputId": "c19339d2-8d94-4cfa-a1d4-746fb9dd7869"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.2.1+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.17.1+cu121)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.3)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.11.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->timm)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->timm)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->timm)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->timm)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->timm)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->timm)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->timm)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->timm)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->timm)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch->timm)\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->timm)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.2.0)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->timm)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install timm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vKvz1SWuutef"
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio  # Installs PyTorch and its vision and audio libraries\n",
    "!pip install opencv-python-headless  # Sometimes 'opencv-python' might not work well in headless environments like servers\n",
    "!pip install joblib pandas numpy matplotlib\n",
    "!pip install torchmetrics  # For the R2Score and other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gKndEoq0PExJ"
   },
   "outputs": [],
   "source": [
    "# # Unzip the dataset\n",
    "\n",
    "!unzip planttraits2024.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-xiZ-tWtmJL"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v3 as imageio\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import timm\n",
    "import glob\n",
    "import torchmetrics\n",
    "import time\n",
    "import psutil\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable progress_apply for pandas\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration class to store all hyperparameters and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MnIkZLeHvd0I"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "class Config():\n",
    "    IMAGE_SIZE = 384\n",
    "    BACKBONE = 'swin_large_patch4_window12_384.ms_in22k_ft_in1k'\n",
    "    TARGET_COLUMNS = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n",
    "    N_TARGETS = len(TARGET_COLUMNS)\n",
    "    BATCH_SIZE = 10\n",
    "    LR_MAX = 1e-4\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    N_EPOCHS = 10\n",
    "    TRAIN_MODEL = True\n",
    "    IS_INTERACTIVE = os.getenv('KAGGLE_KERNEL_RUN_TYPE', 'Interactive') == 'Interactive'\n",
    "\n",
    "CONFIG = Config()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set device to GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHd5SH1Hz9on"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LF02Z-7tsh_"
   },
   "outputs": [],
   "source": [
    "# Load and preprocess training data\n",
    "train = pd.read_csv('train.csv')\n",
    "train['file_path'] = train['id'].apply(lambda s: f'train_images/{s}.jpeg')\n",
    "train['jpeg_bytes'] = train['file_path'].progress_apply(lambda fp: open(fp, 'rb').read())\n",
    "train.to_pickle('train.pkl')\n",
    "\n",
    "# Filter out outliers based on quantiles\n",
    "for column in CONFIG.TARGET_COLUMNS:\n",
    "    lower_quantile = train[column].quantile(0.0325)\n",
    "    upper_quantile = train[column].quantile(0.968)\n",
    "    train = train[(train[column] >= lower_quantile) & (train[column] <= upper_quantile)]\n",
    "\n",
    "CONFIG.N_TRAIN_SAMPLES = len(train)\n",
    "CONFIG.N_STEPS_PER_EPOCH = (CONFIG.N_TRAIN_SAMPLES // CONFIG.BATCH_SIZE)\n",
    "CONFIG.N_STEPS = CONFIG.N_STEPS_PER_EPOCH * CONFIG.N_EPOCHS + 1\n",
    "\n",
    "\n",
    "# Load and preprocess test data\n",
    "test = pd.read_csv('test.csv')\n",
    "test['file_path'] = test['id'].apply(lambda s: f'test_images/{s}.jpeg')\n",
    "test['jpeg_bytes'] = test['file_path'].progress_apply(lambda fp: open(fp, 'rb').read())\n",
    "test.to_pickle('test.pkl')\n",
    "\n",
    "#print('N_TRAIN_SAMPLES:', len(train), 'N_TEST_SAMPLES:', len(test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare target values and apply logarithmic transformation where necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G2ERIwUStslC"
   },
   "outputs": [],
   "source": [
    "LOG_FEATURES = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n",
    "\n",
    "y_train = np.zeros_like(train[CONFIG.TARGET_COLUMNS], dtype=np.float32)\n",
    "for target_idx, target in enumerate(CONFIG.TARGET_COLUMNS):\n",
    "    v = train[target].values\n",
    "    if target in LOG_FEATURES:\n",
    "        v = np.log10(v)\n",
    "    y_train[:, target_idx] = v\n",
    "\n",
    "SCALER = StandardScaler()\n",
    "y_train = SCALER.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2IS4upX0tsng"
   },
   "outputs": [],
   "source": [
    "# Define image normalization parameters\n",
    "\n",
    "MEAN = np.array([0.485, 0.456, 0.406])\n",
    "STD = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "# Define transformations for training and testing datasets\n",
    "TRAIN_TRANSFORMS = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomSizedCrop(\n",
    "            [448, 512],\n",
    "            CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE, w2h_ratio=1.0, p=0.75),\n",
    "        A.Resize(CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.25),\n",
    "        A.ImageCompression(quality_lower=85, quality_upper=100, p=0.25),\n",
    "        A.ToFloat(),\n",
    "        A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "TEST_TRANSFORMS = A.Compose([\n",
    "        A.Resize(CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE),\n",
    "        A.ToFloat(),\n",
    "        A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n",
    "        ToTensorV2(),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Dataset class for loading and transforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, X_jpeg_bytes, y, transforms=None):\n",
    "        self.X_jpeg_bytes = X_jpeg_bytes\n",
    "        self.y = y\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_jpeg_bytes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X_sample = self.transforms(\n",
    "            image=imageio.imread(self.X_jpeg_bytes[index]),\n",
    "        )['image']\n",
    "        y_sample = self.y[index]\n",
    "\n",
    "        return X_sample, y_sample\n",
    "\n",
    "    \n",
    "# Create training and testing datasets and dataloaders    \n",
    "train_dataset = Dataset(\n",
    "    train['jpeg_bytes'].values,\n",
    "    y_train,\n",
    "    TRAIN_TRANSFORMS,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CONFIG.BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=psutil.cpu_count(),\n",
    ")\n",
    "\n",
    "test_dataset = Dataset(\n",
    "    test['jpeg_bytes'].values,\n",
    "    test['id'].values,\n",
    "    TEST_TRANSFORMS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model class - Swin Transformer and Training Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxcV9J6ttsqA"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\n",
    "                CONFIG.BACKBONE,\n",
    "                num_classes=CONFIG.N_TARGETS,\n",
    "                pretrained=True)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.backbone(inputs)\n",
    "\n",
    "# Initialize the model and move to GPU if available    \n",
    "model = Model()\n",
    "model = model.to('cuda')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVhpYT48t10B"
   },
   "outputs": [],
   "source": [
    "# Learning rate scheduler function\n",
    "def get_lr_scheduler(optimizer):\n",
    "    return torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer=optimizer,\n",
    "        max_lr=CONFIG.LR_MAX,\n",
    "        total_steps=CONFIG.N_STEPS,\n",
    "        pct_start=0.1,\n",
    "        anneal_strategy='cos',\n",
    "        div_factor=1e1,\n",
    "        final_div_factor=1e1,\n",
    "    )\n",
    "\n",
    "\n",
    "# Utility class for tracking average metrics\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        self.sum += val.sum()\n",
    "        self.count += val.numel()\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "# Define metrics and loss functions\n",
    "MAE = torchmetrics.regression.MeanAbsoluteError().to('cuda')\n",
    "R2 = torchmetrics.regression.R2Score(num_outputs=CONFIG.N_TARGETS, multioutput='uniform_average').to('cuda')\n",
    "LOSS = AverageMeter()\n",
    "\n",
    "Y_MEAN = torch.tensor(y_train).mean(dim=0).to('cuda')\n",
    "EPS = torch.tensor([1e-6]).to('cuda')\n",
    "\n",
    "def r2_loss(y_pred, y_true):\n",
    "    ss_res = torch.sum((y_true - y_pred)**2, dim=0)\n",
    "    ss_total = torch.sum((y_true - Y_MEAN)**2, dim=0)\n",
    "    ss_total = torch.maximum(ss_total, EPS)\n",
    "    r2 = torch.mean(ss_res / ss_total)\n",
    "    return r2\n",
    "\n",
    "LOSS_FN = nn.SmoothL1Loss() # r2_loss\n",
    "\n",
    "# Define optimizer and learning rate scheduler\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=model.parameters(),\n",
    "    lr=CONFIG.LR_MAX,\n",
    "    weight_decay=CONFIG.WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "LR_SCHEDULER = get_lr_scheduler(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDz5iLZVt127"
   },
   "outputs": [],
   "source": [
    "print(\"Start Training:\")\n",
    "for epoch in range(CONFIG.N_EPOCHS):\n",
    "    MAE.reset()\n",
    "    R2.reset()\n",
    "    LOSS.reset()\n",
    "    model.train()\n",
    "\n",
    "    for step, (X_batch, y_true) in enumerate(train_dataloader):\n",
    "        X_batch = X_batch.to('cuda')\n",
    "        y_true = y_true.to('cuda')\n",
    "        t_start = time.perf_counter_ns()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = LOSS_FN(y_pred, y_true)\n",
    "        LOSS.update(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        LR_SCHEDULER.step()\n",
    "        MAE.update(y_pred, y_true)\n",
    "        R2.update(y_pred, y_true)\n",
    "\n",
    "        if not CONFIG.IS_INTERACTIVE and (step+1) == CONFIG.N_STEPS_PER_EPOCH:\n",
    "            print(\n",
    "                f'EPOCH {epoch+1:02d}, {step+1:04d}/{CONFIG.N_STEPS_PER_EPOCH} | ' +\n",
    "                f'loss: {LOSS.avg:.4f}, mae: {MAE.compute().item():.4f}, r2: {R2.compute().item():.4f}, ' +\n",
    "                f'step: {(time.perf_counter_ns()-t_start)*1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n",
    "            )\n",
    "        elif CONFIG.IS_INTERACTIVE:\n",
    "            print(\n",
    "                f'\\rEPOCH {epoch+1:02d}, {step+1:04d}/{CONFIG.N_STEPS_PER_EPOCH} | ' +\n",
    "                f'loss: {LOSS.avg:.4f}, mae: {MAE.compute().item():.4f}, r2: {R2.compute().item():.4f}, ' +\n",
    "                f'step: {(time.perf_counter_ns()-t_start)*1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n",
    "                end='\\n' if (step + 1) == CONFIG.N_STEPS_PER_EPOCH else '', flush=True,\n",
    "            )\n",
    "\n",
    "#torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ntdhyl68t150"
   },
   "outputs": [],
   "source": [
    "\n",
    "SUBMISSION_ROWS = []\n",
    "model.eval()\n",
    "\n",
    "for X_sample_test, test_id in tqdm(test_dataset):\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_sample_test.unsqueeze(0).to('cuda')).detach().cpu().numpy()\n",
    "\n",
    "    y_pred = SCALER.inverse_transform(y_pred).squeeze()\n",
    "    row = {'id': test_id}\n",
    "\n",
    "    for k, v in zip(CONFIG.TARGET_COLUMNS, y_pred):\n",
    "        if k in LOG_FEATURES:\n",
    "            row[k.replace('_mean', '')] = 10 ** v\n",
    "        else:\n",
    "            row[k.replace('_mean', '')] = v\n",
    "\n",
    "    SUBMISSION_ROWS.append(row)\n",
    "\n",
    "submission_df = pd.DataFrame(SUBMISSION_ROWS)\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"Submit!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUbOzTRgtssX"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yy9JXkjttsvH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
